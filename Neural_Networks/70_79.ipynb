{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex70 Generating Features through Word Vector Summation\n",
    "import gensim\n",
    "model_path = 'GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to change your eBay password: reset your p...</td>\n",
       "      <td>http://www.pcadvisor.co.uk/how-to/security/352...</td>\n",
       "      <td>PC Advisor</td>\n",
       "      <td>t</td>\n",
       "      <td>dR8KtQ_sdlnCHbMcbG5eCMzpDFPSM</td>\n",
       "      <td>www.pcadvisor.co.uk</td>\n",
       "      <td>1400759267641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crafts retailer Michaels raises $473 mln in IPO</td>\n",
       "      <td>http://money.msn.com/business-news/article.asp...</td>\n",
       "      <td>MSN Money</td>\n",
       "      <td>b</td>\n",
       "      <td>dq6woeC_K7MdAWMDnlFDU_Rjk6KaM</td>\n",
       "      <td>money.msn.com</td>\n",
       "      <td>1403851973928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft Ends Support For Windows XP With Fin...</td>\n",
       "      <td>http://www.techweekeurope.co.uk/news/windows-x...</td>\n",
       "      <td>TechWeekEurope UK</td>\n",
       "      <td>t</td>\n",
       "      <td>dI4n0Nno6NFSZUM7MU77tPw1SXRfM</td>\n",
       "      <td>www.techweekeurope.co.uk</td>\n",
       "      <td>1396992636097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anna Kendrick Raps To Iggy Azalea On 'SNL': Watch</td>\n",
       "      <td>http://www.idolator.com/7513000/snl-the-little...</td>\n",
       "      <td>Idolator\\: All About The Music</td>\n",
       "      <td>e</td>\n",
       "      <td>dUkT9vYJUD0kiZMZY6g65RXJ6R2FM</td>\n",
       "      <td>www.idolator.com</td>\n",
       "      <td>1396882956255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Study: Emperor penguin population to slide due...</td>\n",
       "      <td>http://www.theglobeandmail.com/news/world/stud...</td>\n",
       "      <td>The Globe and Mail</td>\n",
       "      <td>t</td>\n",
       "      <td>dZx6m1MtUT29FcMyc8d7SdNzC8_wM</td>\n",
       "      <td>www.theglobeandmail.com</td>\n",
       "      <td>1404152226968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1  \\\n",
       "0  How to change your eBay password: reset your p...   \n",
       "1    Crafts retailer Michaels raises $473 mln in IPO   \n",
       "2  Microsoft Ends Support For Windows XP With Fin...   \n",
       "3  Anna Kendrick Raps To Iggy Azalea On 'SNL': Watch   \n",
       "4  Study: Emperor penguin population to slide due...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  http://www.pcadvisor.co.uk/how-to/security/352...   \n",
       "1  http://money.msn.com/business-news/article.asp...   \n",
       "2  http://www.techweekeurope.co.uk/news/windows-x...   \n",
       "3  http://www.idolator.com/7513000/snl-the-little...   \n",
       "4  http://www.theglobeandmail.com/news/world/stud...   \n",
       "\n",
       "                                3  4                              5  \\\n",
       "0                      PC Advisor  t  dR8KtQ_sdlnCHbMcbG5eCMzpDFPSM   \n",
       "1                       MSN Money  b  dq6woeC_K7MdAWMDnlFDU_Rjk6KaM   \n",
       "2               TechWeekEurope UK  t  dI4n0Nno6NFSZUM7MU77tPw1SXRfM   \n",
       "3  Idolator\\: All About The Music  e  dUkT9vYJUD0kiZMZY6g65RXJ6R2FM   \n",
       "4              The Globe and Mail  t  dZx6m1MtUT29FcMyc8d7SdNzC8_wM   \n",
       "\n",
       "                          6              7  \n",
       "0       www.pcadvisor.co.uk  1400759267641  \n",
       "1             money.msn.com  1403851973928  \n",
       "2  www.techweekeurope.co.uk  1396992636097  \n",
       "3          www.idolator.com  1396882956255  \n",
       "4   www.theglobeandmail.com  1404152226968  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('newsCorpora.csv', sep='\\t', header=None)\n",
    "data_df.drop(data_df.columns[0], axis=1, inplace=True)\n",
    "rows = list(range(len(data_df.index)))\n",
    "random.shuffle(rows)\n",
    "data_df = data_df.iloc[rows]\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422419 entries, 0 to 422418\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype   \n",
      "---  ------  --------------   -----   \n",
      " 0   1       422419 non-null  object  \n",
      " 1   2       422419 non-null  object  \n",
      " 2   3       422417 non-null  object  \n",
      " 3   4       422419 non-null  category\n",
      " 4   5       422419 non-null  object  \n",
      " 5   6       422419 non-null  object  \n",
      " 6   7       422419 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(5)\n",
      "memory usage: 19.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.iloc[:, 3] = data_df.iloc[:, 3].astype('category')\n",
    "data_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(text):\n",
    "    text = text.lower()\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in text_tokens if word not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_text = [stemmer.stem(word) for word in filtered_text]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in stemmed_text]\n",
    "    return \" \".join(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.iloc[:, 0] = data_df.iloc[:, 0].apply(data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422419, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame()\n",
    "data['title'] = data_df.iloc[:, 0]\n",
    "data['category'] = data_df.iloc[:, 3]\n",
    "data.category.replace({'b': 0, 't': 1, 'e': 2, 'm': 3}, inplace=True)\n",
    "data['word_count'] = data['title'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400350 entries, 0 to 422418\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   title       400350 non-null  object  \n",
      " 1   category    400350 non-null  category\n",
      " 2   word_count  400350 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = data.duplicated().sum()\n",
    "data = data.drop_duplicates('title')\n",
    "data.shape\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400350, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(data.index), 300))\n",
    "Y = np.zeros((len(data.index), 1))\n",
    "for i in range(len(data.index)):\n",
    "    title = data.iloc[i, 0]\n",
    "    words = title.split(\" \")\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            X[i] += model[word]\n",
    "    Y[i] = data.iloc[i, 1]\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400350, 300)\n",
      "(400350, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "Y = encoder.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ex71 Building Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.90335530e-01 1.41026838e-06 2.09660588e-01 2.47197688e-06]\n",
      "[[5.64868175e-02 1.00794624e-07 1.49848500e-02 1.76676995e-07]\n",
      " [4.32651972e-02 3.30500400e-03 2.77388292e-02 8.23355589e-04]\n",
      " [4.86112034e-02 3.60528614e-13 6.36783249e-01 7.57451065e-09]\n",
      " [6.17937471e-06 1.29168133e-02 1.55054966e-01 2.32501051e-05]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "W = np.random.randn(300, 4)\n",
    "y1 = softmax(np.dot(x_train[0], W))\n",
    "Y_ = softmax(x_train[:4].dot(W))\n",
    "print(y1)\n",
    "print(Y_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ex72 Calculating loss and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23529770228467506\n",
      "11.976617888773287\n",
      "[[-3.69697968e-01 -6.59686087e-07 -9.80736539e-02 -1.15632512e-06]\n",
      " [ 2.73607369e-01  4.88222793e-07  7.25826937e-02  8.55777151e-07]\n",
      " [ 4.58456352e-01  8.18065837e-07  1.21619521e-01  1.43393971e-06]\n",
      " ...\n",
      " [ 2.79974818e-01  4.99584819e-07  7.42718538e-02  8.75692980e-07]\n",
      " [ 2.99270119e-01  5.34015199e-07  7.93905204e-02  9.36043978e-07]\n",
      " [ 2.08389251e-01  3.71848108e-07  5.52816003e-02  6.51790778e-07]]\n",
      "[[ 0.49454089 -1.08987941  0.7126693  -0.01199485]\n",
      " [-0.30067288 -0.57743022  0.19057002 -0.72070649]\n",
      " [-0.54507016 -0.04722064  0.04292641 -0.11804916]\n",
      " ...\n",
      " [-0.3281395  -0.1161595   0.11562685  0.18520813]\n",
      " [-0.38085642  0.4553297  -0.45538224  0.01634152]\n",
      " [-0.28179026  0.65796117 -0.51749146 -0.20049544]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculate the probability of each category\n",
    "y_hat_1 = softmax(np.dot(x_train[0], W))\n",
    "y_hat = softmax(x_train[:4].dot(W))\n",
    "#calculate the cross entropy loss\n",
    "# li=−log[probability that sample xi is classified as yi]\n",
    "loss_1 = -np.log((y_hat_1).dot(y_train[0]))\n",
    "loss = -np.mean(np.sum(y_train[:4] * np.log(y_hat), axis=1))\n",
    "#calculate the gradients\n",
    "dW1=np.outer(x_train[0],y_hat_1)\n",
    "dW = np.dot(x_train[:4].T, y_hat - y_train[:4])\n",
    "print(loss_1)\n",
    "print(loss)\n",
    "print(dW1)\n",
    "print(dW)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex73. Learning with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.177969835393046"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(300, 4)\n",
    "W.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #Shuffle training data\n",
    "    indices = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    \n",
    "    #iterate over training set\n",
    "    for i in range(x_train.shape[0]):\n",
    "        #calculate the probability of each category\n",
    "        y_hat = softmax(np.dot(x_train[i], W))\n",
    "        #calculate the cross entropy loss\n",
    "        loss = -np.log((y_hat).dot(y_train[i]))\n",
    "        #calculate the gradients\n",
    "        dW = np.outer(x_train[i], y_hat - y_train[i])\n",
    "        #update the parameters\n",
    "        W = W - learning_rate * dW\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81604972, -0.68529429, -0.70263256, -0.7084503 ],\n",
       "       [-0.33537016, -0.2625278 ,  0.00609271, -0.47723396],\n",
       "       [ 0.15838749,  0.53823929,  0.22105892,  0.57908957],\n",
       "       ...,\n",
       "       [ 0.47439217,  0.43720439,  0.14207118,  0.45631109],\n",
       "       [ 0.54166941,  0.6005626 ,  0.72537432,  0.4875002 ],\n",
       "       [-0.93499931, -0.70817409, -0.48378124, -0.29241939]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 74. Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7954289996253279\n",
      "Validation accuracy:  0.7958286499313101\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.argmax(x_train.dot(W), axis=1)\n",
    "accuracy_train = np.mean(y_train_pred == np.argmax(y_train, axis=1))\n",
    "print(\"Training accuracy: \", accuracy_train)\n",
    "y_eval_pred = np.argmax(x_val.dot(W), axis=1)\n",
    "accuracy_eval = np.mean(y_eval_pred == np.argmax(y_val, axis=1))\n",
    "print(\"Validation accuracy: \", accuracy_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75. Plotting loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 72.8036, Train acc: 0.1658, Eval loss: 82.5762, Eval acc: 0.1651\n",
      "Epoch: 1, Train loss: 67.9094, Train acc: 0.5676, Eval loss: 7.9035, Eval acc: 0.5683\n",
      "Epoch: 2, Train loss: 34.3908, Train acc: 0.5945, Eval loss: 5.7834, Eval acc: 0.5951\n",
      "Epoch: 3, Train loss: 24.3243, Train acc: 0.5938, Eval loss: 5.6004, Eval acc: 0.5935\n",
      "Epoch: 4, Train loss: 15.8774, Train acc: 0.5950, Eval loss: 5.5376, Eval acc: 0.5944\n",
      "Epoch: 5, Train loss: 13.0709, Train acc: 0.5945, Eval loss: 5.3584, Eval acc: 0.5944\n",
      "Epoch: 6, Train loss: 12.4444, Train acc: 0.5958, Eval loss: 5.2565, Eval acc: 0.5959\n",
      "Epoch: 7, Train loss: 11.9594, Train acc: 0.5940, Eval loss: 5.3531, Eval acc: 0.5943\n",
      "Epoch: 8, Train loss: 9.1390, Train acc: 0.5896, Eval loss: 5.3822, Eval acc: 0.5893\n",
      "Epoch: 9, Train loss: 14.6703, Train acc: 0.5972, Eval loss: 5.3231, Eval acc: 0.5974\n",
      "Epoch: 10, Train loss: 8.1325, Train acc: 0.5934, Eval loss: 5.3108, Eval acc: 0.5928\n",
      "Epoch: 11, Train loss: 8.7894, Train acc: 0.5874, Eval loss: 5.2980, Eval acc: 0.5869\n",
      "Epoch: 12, Train loss: 6.8861, Train acc: 0.5868, Eval loss: 5.3402, Eval acc: 0.5860\n",
      "Epoch: 13, Train loss: 7.4140, Train acc: 0.5942, Eval loss: 5.2735, Eval acc: 0.5933\n",
      "Epoch: 14, Train loss: 8.2962, Train acc: 0.5941, Eval loss: 5.2865, Eval acc: 0.5943\n",
      "Epoch: 15, Train loss: 7.9757, Train acc: 0.5911, Eval loss: 5.2945, Eval acc: 0.5903\n",
      "Epoch: 16, Train loss: 8.6328, Train acc: 0.5961, Eval loss: 5.3379, Eval acc: 0.5970\n",
      "Epoch: 17, Train loss: 5.7250, Train acc: 0.5865, Eval loss: 5.3387, Eval acc: 0.5856\n",
      "Epoch: 18, Train loss: 14.6007, Train acc: 0.5947, Eval loss: 5.3218, Eval acc: 0.5959\n",
      "Epoch: 19, Train loss: 5.7178, Train acc: 0.5925, Eval loss: 5.3581, Eval acc: 0.5916\n",
      "Epoch: 20, Train loss: 9.7765, Train acc: 0.5992, Eval loss: 5.2297, Eval acc: 0.5996\n",
      "Epoch: 21, Train loss: 11.4764, Train acc: 0.5985, Eval loss: 5.2855, Eval acc: 0.5980\n",
      "Epoch: 22, Train loss: 9.4303, Train acc: 0.5955, Eval loss: 5.2574, Eval acc: 0.5965\n",
      "Epoch: 23, Train loss: 5.6762, Train acc: 0.5906, Eval loss: 5.3331, Eval acc: 0.5911\n",
      "Epoch: 24, Train loss: 10.5466, Train acc: 0.5953, Eval loss: 5.3625, Eval acc: 0.5959\n",
      "Epoch: 25, Train loss: 5.6959, Train acc: 0.5942, Eval loss: 5.2732, Eval acc: 0.5941\n",
      "Epoch: 26, Train loss: 6.6141, Train acc: 0.5918, Eval loss: 5.3370, Eval acc: 0.5924\n",
      "Epoch: 27, Train loss: 8.9347, Train acc: 0.5971, Eval loss: 5.1846, Eval acc: 0.5973\n",
      "Epoch: 28, Train loss: 10.2099, Train acc: 0.5907, Eval loss: 5.2782, Eval acc: 0.5905\n",
      "Epoch: 29, Train loss: 5.6409, Train acc: 0.5929, Eval loss: 5.3002, Eval acc: 0.5930\n",
      "Epoch: 30, Train loss: 7.6153, Train acc: 0.5891, Eval loss: 5.3253, Eval acc: 0.5886\n",
      "Epoch: 31, Train loss: 5.7102, Train acc: 0.5921, Eval loss: 5.3558, Eval acc: 0.5917\n",
      "Epoch: 32, Train loss: 6.5176, Train acc: 0.5924, Eval loss: 5.3435, Eval acc: 0.5925\n",
      "Epoch: 33, Train loss: 5.9216, Train acc: 0.5912, Eval loss: 5.3002, Eval acc: 0.5913\n",
      "Epoch: 34, Train loss: 9.2698, Train acc: 0.5937, Eval loss: 5.3886, Eval acc: 0.5931\n",
      "Epoch: 35, Train loss: 7.1437, Train acc: 0.5946, Eval loss: 5.2261, Eval acc: 0.5944\n",
      "Epoch: 36, Train loss: 14.6256, Train acc: 0.5975, Eval loss: 5.3103, Eval acc: 0.5980\n",
      "Epoch: 37, Train loss: 5.6921, Train acc: 0.5941, Eval loss: 5.3103, Eval acc: 0.5942\n",
      "Epoch: 38, Train loss: 5.6802, Train acc: 0.5882, Eval loss: 5.3625, Eval acc: 0.5878\n",
      "Epoch: 39, Train loss: 5.6956, Train acc: 0.5946, Eval loss: 5.3652, Eval acc: 0.5942\n",
      "Epoch: 40, Train loss: 5.6477, Train acc: 0.5908, Eval loss: 5.2764, Eval acc: 0.5902\n",
      "Epoch: 41, Train loss: 6.2544, Train acc: 0.5940, Eval loss: 5.2546, Eval acc: 0.5942\n",
      "Epoch: 42, Train loss: 8.6874, Train acc: 0.5881, Eval loss: 5.3048, Eval acc: 0.5878\n",
      "Epoch: 43, Train loss: 6.3564, Train acc: 0.5891, Eval loss: 5.2867, Eval acc: 0.5890\n",
      "Epoch: 44, Train loss: 6.6921, Train acc: 0.5943, Eval loss: 5.3023, Eval acc: 0.5938\n",
      "Epoch: 45, Train loss: 11.5856, Train acc: 0.5965, Eval loss: 5.3065, Eval acc: 0.5967\n",
      "Epoch: 46, Train loss: 5.7298, Train acc: 0.5922, Eval loss: 5.3520, Eval acc: 0.5921\n",
      "Epoch: 47, Train loss: 8.1490, Train acc: 0.5916, Eval loss: 5.2960, Eval acc: 0.5918\n",
      "Epoch: 48, Train loss: 9.0169, Train acc: 0.5898, Eval loss: 5.2630, Eval acc: 0.5892\n",
      "Epoch: 49, Train loss: 10.7342, Train acc: 0.5926, Eval loss: 5.3465, Eval acc: 0.5924\n",
      "Epoch: 50, Train loss: 11.5967, Train acc: 0.5891, Eval loss: 5.2991, Eval acc: 0.5890\n",
      "Epoch: 51, Train loss: 6.2199, Train acc: 0.5946, Eval loss: 5.3577, Eval acc: 0.5945\n",
      "Epoch: 52, Train loss: 5.6921, Train acc: 0.5884, Eval loss: 5.3303, Eval acc: 0.5874\n",
      "Epoch: 53, Train loss: 6.1771, Train acc: 0.5883, Eval loss: 5.3303, Eval acc: 0.5883\n",
      "Epoch: 54, Train loss: 5.6104, Train acc: 0.5942, Eval loss: 5.2200, Eval acc: 0.5941\n",
      "Epoch: 55, Train loss: 10.3655, Train acc: 0.5940, Eval loss: 5.3156, Eval acc: 0.5943\n",
      "Epoch: 56, Train loss: 13.6600, Train acc: 0.5988, Eval loss: 5.3084, Eval acc: 0.5991\n",
      "Epoch: 57, Train loss: 8.3877, Train acc: 0.5892, Eval loss: 5.3607, Eval acc: 0.5887\n",
      "Epoch: 58, Train loss: 6.7193, Train acc: 0.5919, Eval loss: 5.3015, Eval acc: 0.5920\n",
      "Epoch: 59, Train loss: 5.6964, Train acc: 0.5895, Eval loss: 5.3068, Eval acc: 0.5896\n",
      "Epoch: 60, Train loss: 12.4150, Train acc: 0.5951, Eval loss: 5.2999, Eval acc: 0.5945\n",
      "Epoch: 61, Train loss: 5.6323, Train acc: 0.5949, Eval loss: 5.2764, Eval acc: 0.5955\n",
      "Epoch: 62, Train loss: 5.7448, Train acc: 0.5869, Eval loss: 5.3473, Eval acc: 0.5862\n",
      "Epoch: 63, Train loss: 11.7386, Train acc: 0.5963, Eval loss: 5.2924, Eval acc: 0.5963\n",
      "Epoch: 64, Train loss: 8.0107, Train acc: 0.5943, Eval loss: 5.2381, Eval acc: 0.5947\n",
      "Epoch: 65, Train loss: 15.9983, Train acc: 0.5991, Eval loss: 5.2587, Eval acc: 0.5988\n",
      "Epoch: 66, Train loss: 5.6944, Train acc: 0.5938, Eval loss: 5.2767, Eval acc: 0.5934\n",
      "Epoch: 67, Train loss: 9.0639, Train acc: 0.5906, Eval loss: 5.3493, Eval acc: 0.5905\n",
      "Epoch: 68, Train loss: 5.7560, Train acc: 0.5831, Eval loss: 5.3925, Eval acc: 0.5829\n",
      "Epoch: 69, Train loss: 13.0856, Train acc: 0.5943, Eval loss: 5.3095, Eval acc: 0.5938\n",
      "Epoch: 70, Train loss: 6.6578, Train acc: 0.5975, Eval loss: 5.2817, Eval acc: 0.5982\n",
      "Epoch: 71, Train loss: 17.4161, Train acc: 0.5963, Eval loss: 5.2277, Eval acc: 0.5971\n",
      "Epoch: 72, Train loss: 11.9808, Train acc: 0.5976, Eval loss: 5.2652, Eval acc: 0.5973\n",
      "Epoch: 73, Train loss: 5.6425, Train acc: 0.5825, Eval loss: 5.2944, Eval acc: 0.5814\n",
      "Epoch: 74, Train loss: 14.8423, Train acc: 0.6014, Eval loss: 5.2279, Eval acc: 0.6020\n",
      "Epoch: 75, Train loss: 5.7361, Train acc: 0.5812, Eval loss: 5.4418, Eval acc: 0.5800\n",
      "Epoch: 76, Train loss: 9.0154, Train acc: 0.5946, Eval loss: 5.2960, Eval acc: 0.5950\n",
      "Epoch: 77, Train loss: 6.3043, Train acc: 0.5918, Eval loss: 5.2667, Eval acc: 0.5914\n",
      "Epoch: 78, Train loss: 9.2139, Train acc: 0.5928, Eval loss: 5.3267, Eval acc: 0.5922\n",
      "Epoch: 79, Train loss: 9.5869, Train acc: 0.5934, Eval loss: 5.3085, Eval acc: 0.5933\n",
      "Epoch: 80, Train loss: 9.3624, Train acc: 0.5945, Eval loss: 5.3054, Eval acc: 0.5946\n",
      "Epoch: 81, Train loss: 5.8863, Train acc: 0.5864, Eval loss: 5.4055, Eval acc: 0.5852\n",
      "Epoch: 82, Train loss: 10.5476, Train acc: 0.5989, Eval loss: 5.2661, Eval acc: 0.5991\n",
      "Epoch: 83, Train loss: 7.7144, Train acc: 0.5939, Eval loss: 5.2690, Eval acc: 0.5936\n",
      "Epoch: 84, Train loss: 10.5053, Train acc: 0.5961, Eval loss: 5.2085, Eval acc: 0.5961\n",
      "Epoch: 85, Train loss: 10.0425, Train acc: 0.5928, Eval loss: 5.3171, Eval acc: 0.5927\n",
      "Epoch: 86, Train loss: 12.2593, Train acc: 0.5908, Eval loss: 5.3450, Eval acc: 0.5909\n",
      "Epoch: 87, Train loss: 5.7126, Train acc: 0.5897, Eval loss: 5.3576, Eval acc: 0.5896\n",
      "Epoch: 88, Train loss: 5.7065, Train acc: 0.5795, Eval loss: 5.3546, Eval acc: 0.5788\n",
      "Epoch: 89, Train loss: 9.1188, Train acc: 0.5944, Eval loss: 5.2866, Eval acc: 0.5940\n",
      "Epoch: 90, Train loss: 13.2940, Train acc: 0.5958, Eval loss: 5.2287, Eval acc: 0.5958\n",
      "Epoch: 91, Train loss: 5.7130, Train acc: 0.5897, Eval loss: 5.2704, Eval acc: 0.5901\n",
      "Epoch: 92, Train loss: 11.7575, Train acc: 0.5989, Eval loss: 5.3364, Eval acc: 0.5988\n",
      "Epoch: 93, Train loss: 8.5316, Train acc: 0.5938, Eval loss: 5.3028, Eval acc: 0.5942\n",
      "Epoch: 94, Train loss: 8.1242, Train acc: 0.5972, Eval loss: 5.2588, Eval acc: 0.5971\n",
      "Epoch: 95, Train loss: 10.8612, Train acc: 0.5888, Eval loss: 5.4061, Eval acc: 0.5891\n",
      "Epoch: 96, Train loss: 8.2970, Train acc: 0.5966, Eval loss: 5.2620, Eval acc: 0.5976\n",
      "Epoch: 97, Train loss: 7.0719, Train acc: 0.5910, Eval loss: 5.2835, Eval acc: 0.5909\n",
      "Epoch: 98, Train loss: 8.3852, Train acc: 0.5869, Eval loss: 5.3151, Eval acc: 0.5867\n",
      "Epoch: 99, Train loss: 5.7472, Train acc: 0.5859, Eval loss: 5.3913, Eval acc: 0.5864\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W2 = np.random.randn(300, 4)\n",
    "eta = 0.001\n",
    "n_epochs = 100\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "train_acc = []\n",
    "eval_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    indices = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    # compute loss and accuracy on training set\n",
    "    train_probs = softmax(x_train.dot(W2))\n",
    "    mask = train_probs > 0\n",
    "    train_probs = np.where(mask, train_probs, 1e-9)\n",
    "    train_loss.append(-np.mean(y_train * np.log(train_probs)))\n",
    "    train_pred = np.argmax(train_probs, axis=1)\n",
    "    mask = train_pred > 0\n",
    "    train_pred = np.where(mask, train_pred, 1e-9)\n",
    "    train_acc.append(np.mean(train_pred == np.argmax(y_train, axis=1)))\n",
    "    # compute loss and accuracy on validation set\n",
    "    eval_probs = softmax(x_val.dot(W2))\n",
    "    mask = eval_probs > 0\n",
    "    eval_probs = np.where(mask, eval_probs, 1e-9)\n",
    "    eval_loss.append(-np.mean(y_val * np.log(eval_probs)))\n",
    "    eval_pred = np.argmax(eval_probs, axis=1)\n",
    "    mask = eval_pred > 0\n",
    "    eval_pred = np.where(mask, eval_pred, 1e-9)\n",
    "    eval_acc.append(np.mean(eval_pred == np.argmax(y_val, axis=1)))\n",
    "    #update the parameters\n",
    "    for i in range(x_train.shape[0]):\n",
    "        y_hat = softmax(np.dot(x_train[i], W2))\n",
    "        loss = -np.log((y_hat).dot(y_train[i]))\n",
    "        dW = np.outer(x_train[i], y_hat - y_train[i])\n",
    "        W2 = W2 - eta * dW\n",
    "    #print progress\n",
    "    print(\"Epoch: %d, Train loss: %.4f, Train acc: %.4f, Eval loss: %.4f, Eval acc: %.4f\" % (epoch, train_loss[-1], train_acc[-1], eval_loss[-1], eval_acc[-1]))\n",
    "    \n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(eval_loss, label='eval')\n",
    "plt.plot(train_acc, label='train acc')\n",
    "plt.plot(eval_acc, label='eval acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('value')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 76. Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 207128378.1852, Train acc: 0.2271, Eval loss: 20452132.1188, Eval acc: 0.2301\n",
      "Epoch: 1, Train loss: 143724681.5858, Train acc: 0.7653, Eval loss: 11942489.4002, Eval acc: 0.7646\n",
      "Epoch: 2, Train loss: 108683604.6328, Train acc: 0.7951, Eval loss: 7637063.4229, Eval acc: 0.7943\n",
      "Epoch: 3, Train loss: 108227754.9302, Train acc: 0.8039, Eval loss: 6616813.1647, Eval acc: 0.8032\n",
      "Epoch: 4, Train loss: 104647177.6811, Train acc: 0.8056, Eval loss: 6464926.1432, Eval acc: 0.8046\n",
      "Epoch: 5, Train loss: 102107663.7096, Train acc: 0.8073, Eval loss: 6152051.4501, Eval acc: 0.8058\n",
      "Epoch: 6, Train loss: 106035254.8185, Train acc: 0.8063, Eval loss: 6303539.7090, Eval acc: 0.8046\n",
      "Epoch: 7, Train loss: 106518402.5371, Train acc: 0.8064, Eval loss: 5679543.4387, Eval acc: 0.8039\n",
      "Epoch: 8, Train loss: 103984185.8772, Train acc: 0.8072, Eval loss: 5866733.4004, Eval acc: 0.8050\n",
      "Epoch: 9, Train loss: 101739776.1591, Train acc: 0.8076, Eval loss: 5532978.2845, Eval acc: 0.8045\n",
      "Epoch: 10, Train loss: 95496132.1624, Train acc: 0.8066, Eval loss: 6893910.5844, Eval acc: 0.8045\n",
      "Epoch: 11, Train loss: 97977882.5851, Train acc: 0.8075, Eval loss: 5862124.0683, Eval acc: 0.8062\n",
      "Epoch: 12, Train loss: 100978956.3216, Train acc: 0.8076, Eval loss: 4643894.2217, Eval acc: 0.8066\n",
      "Epoch: 13, Train loss: 105897877.3333, Train acc: 0.8069, Eval loss: 5768434.8179, Eval acc: 0.8054\n",
      "Epoch: 14, Train loss: 106339931.2188, Train acc: 0.8066, Eval loss: 5774337.1070, Eval acc: 0.8061\n",
      "Epoch: 15, Train loss: 100932617.1004, Train acc: 0.8077, Eval loss: 6039421.0723, Eval acc: 0.8061\n",
      "Epoch: 16, Train loss: 101930495.1793, Train acc: 0.8078, Eval loss: 6013514.9196, Eval acc: 0.8067\n",
      "Epoch: 17, Train loss: 97811281.5812, Train acc: 0.8070, Eval loss: 5580933.2059, Eval acc: 0.8061\n",
      "Epoch: 18, Train loss: 101667643.3475, Train acc: 0.8076, Eval loss: 5794039.2074, Eval acc: 0.8062\n",
      "Epoch: 19, Train loss: 95486697.2935, Train acc: 0.8066, Eval loss: 6108517.4583, Eval acc: 0.8059\n",
      "Epoch: 20, Train loss: 95116273.7181, Train acc: 0.8068, Eval loss: 5474958.4054, Eval acc: 0.8053\n",
      "Epoch: 21, Train loss: 100905511.3518, Train acc: 0.8077, Eval loss: 5734805.6085, Eval acc: 0.8064\n",
      "Epoch: 22, Train loss: 87783377.1393, Train acc: 0.8039, Eval loss: 6268507.3559, Eval acc: 0.8028\n",
      "Epoch: 23, Train loss: 104909743.4369, Train acc: 0.8069, Eval loss: 4933636.2032, Eval acc: 0.8065\n",
      "Epoch: 24, Train loss: 90073808.6892, Train acc: 0.8070, Eval loss: 6336168.1756, Eval acc: 0.8056\n",
      "Epoch: 25, Train loss: 105487305.3078, Train acc: 0.8067, Eval loss: 5297811.0839, Eval acc: 0.8058\n",
      "Epoch: 26, Train loss: 100492201.0483, Train acc: 0.8047, Eval loss: 5277084.8514, Eval acc: 0.8040\n",
      "Epoch: 27, Train loss: 97690340.2422, Train acc: 0.8071, Eval loss: 6408253.9558, Eval acc: 0.8051\n",
      "Epoch: 28, Train loss: 97926688.6350, Train acc: 0.8071, Eval loss: 6112474.0482, Eval acc: 0.8063\n",
      "Epoch: 29, Train loss: 98860409.2265, Train acc: 0.8065, Eval loss: 4752386.5506, Eval acc: 0.8062\n",
      "Epoch: 30, Train loss: 108070930.4420, Train acc: 0.8073, Eval loss: 4870186.6655, Eval acc: 0.8058\n",
      "Epoch: 31, Train loss: 96211482.1150, Train acc: 0.8064, Eval loss: 5225180.2619, Eval acc: 0.8055\n",
      "Epoch: 32, Train loss: 102662588.8516, Train acc: 0.8076, Eval loss: 5537658.2744, Eval acc: 0.8067\n",
      "Epoch: 33, Train loss: 96374207.6693, Train acc: 0.8066, Eval loss: 5287011.7817, Eval acc: 0.8049\n",
      "Epoch: 34, Train loss: 99984732.3010, Train acc: 0.8077, Eval loss: 5644698.8805, Eval acc: 0.8053\n",
      "Epoch: 35, Train loss: 102099178.8183, Train acc: 0.8069, Eval loss: 6173318.1913, Eval acc: 0.8060\n",
      "Epoch: 36, Train loss: 105783772.9632, Train acc: 0.8070, Eval loss: 6137413.2163, Eval acc: 0.8053\n",
      "Epoch: 37, Train loss: 102825308.4494, Train acc: 0.8073, Eval loss: 5642306.8380, Eval acc: 0.8055\n",
      "Epoch: 38, Train loss: 102366109.3587, Train acc: 0.8061, Eval loss: 5298733.5301, Eval acc: 0.8042\n",
      "Epoch: 39, Train loss: 105180945.1594, Train acc: 0.8013, Eval loss: 3843866.0078, Eval acc: 0.8008\n",
      "Epoch: 40, Train loss: 104208041.1819, Train acc: 0.8070, Eval loss: 5852494.8109, Eval acc: 0.8056\n",
      "Epoch: 41, Train loss: 100661633.9741, Train acc: 0.8072, Eval loss: 5515018.4473, Eval acc: 0.8054\n",
      "Epoch: 42, Train loss: 103520979.1847, Train acc: 0.8076, Eval loss: 5562985.4135, Eval acc: 0.8061\n",
      "Epoch: 43, Train loss: 101133363.2660, Train acc: 0.8071, Eval loss: 5021440.2182, Eval acc: 0.8056\n",
      "Epoch: 44, Train loss: 93011394.4568, Train acc: 0.8071, Eval loss: 5477158.0241, Eval acc: 0.8056\n",
      "Epoch: 45, Train loss: 98197228.3870, Train acc: 0.8068, Eval loss: 5111005.6892, Eval acc: 0.8047\n",
      "Epoch: 46, Train loss: 99608530.4382, Train acc: 0.8071, Eval loss: 5733245.8208, Eval acc: 0.8052\n",
      "Epoch: 47, Train loss: 100721637.7579, Train acc: 0.8070, Eval loss: 5505377.4845, Eval acc: 0.8055\n",
      "Epoch: 48, Train loss: 92849824.9816, Train acc: 0.8076, Eval loss: 6802474.6615, Eval acc: 0.8046\n",
      "Epoch: 49, Train loss: 100165144.8748, Train acc: 0.8073, Eval loss: 5514974.0729, Eval acc: 0.8065\n",
      "Epoch: 50, Train loss: 101353785.0417, Train acc: 0.8068, Eval loss: 5119803.9017, Eval acc: 0.8058\n",
      "Epoch: 51, Train loss: 99591410.0734, Train acc: 0.8065, Eval loss: 5641038.3340, Eval acc: 0.8058\n",
      "Epoch: 52, Train loss: 94916498.0745, Train acc: 0.8073, Eval loss: 5077012.6556, Eval acc: 0.8047\n",
      "Epoch: 53, Train loss: 96131361.1002, Train acc: 0.8076, Eval loss: 6262540.7234, Eval acc: 0.8062\n",
      "Epoch: 54, Train loss: 101133168.5425, Train acc: 0.8066, Eval loss: 4844852.6053, Eval acc: 0.8051\n",
      "Epoch: 55, Train loss: 101583068.3256, Train acc: 0.8078, Eval loss: 6337575.0326, Eval acc: 0.8048\n",
      "Epoch: 56, Train loss: 92193618.5778, Train acc: 0.8068, Eval loss: 5851702.6477, Eval acc: 0.8049\n",
      "Epoch: 57, Train loss: 102651759.8835, Train acc: 0.8078, Eval loss: 5188405.4324, Eval acc: 0.8055\n",
      "Epoch: 58, Train loss: 97628971.1223, Train acc: 0.8073, Eval loss: 5755286.1784, Eval acc: 0.8066\n",
      "Epoch: 59, Train loss: 102278909.9203, Train acc: 0.8072, Eval loss: 5069402.1354, Eval acc: 0.8057\n",
      "Epoch: 60, Train loss: 97445203.4275, Train acc: 0.8073, Eval loss: 5768172.7234, Eval acc: 0.8061\n",
      "Epoch: 61, Train loss: 105675170.4240, Train acc: 0.8067, Eval loss: 5486148.5809, Eval acc: 0.8059\n",
      "Epoch: 62, Train loss: 100240887.9420, Train acc: 0.8069, Eval loss: 5016082.4183, Eval acc: 0.8052\n",
      "Epoch: 63, Train loss: 101286197.8393, Train acc: 0.8069, Eval loss: 5152511.6413, Eval acc: 0.8057\n",
      "Epoch: 64, Train loss: 101395654.9973, Train acc: 0.8069, Eval loss: 5893893.6259, Eval acc: 0.8055\n",
      "Epoch: 65, Train loss: 106773411.9425, Train acc: 0.8060, Eval loss: 5122579.7793, Eval acc: 0.8055\n",
      "Epoch: 66, Train loss: 94195785.9917, Train acc: 0.8072, Eval loss: 5907683.9180, Eval acc: 0.8052\n",
      "Epoch: 67, Train loss: 101082978.3795, Train acc: 0.8053, Eval loss: 6657752.3983, Eval acc: 0.8037\n",
      "Epoch: 68, Train loss: 99305214.7722, Train acc: 0.8076, Eval loss: 5964526.3764, Eval acc: 0.8066\n",
      "Epoch: 69, Train loss: 98125042.5802, Train acc: 0.8076, Eval loss: 6230457.2674, Eval acc: 0.8056\n",
      "Epoch: 70, Train loss: 105238997.2951, Train acc: 0.8069, Eval loss: 5168237.5684, Eval acc: 0.8051\n",
      "Epoch: 71, Train loss: 98424186.8656, Train acc: 0.8065, Eval loss: 4897746.8181, Eval acc: 0.8041\n",
      "Epoch: 72, Train loss: 105582442.1505, Train acc: 0.8070, Eval loss: 5938569.9586, Eval acc: 0.8051\n",
      "Epoch: 73, Train loss: 95644258.0525, Train acc: 0.8069, Eval loss: 5473466.9636, Eval acc: 0.8066\n",
      "Epoch: 74, Train loss: 97388065.6082, Train acc: 0.8076, Eval loss: 5887577.0064, Eval acc: 0.8062\n",
      "Epoch: 75, Train loss: 107314788.7050, Train acc: 0.8075, Eval loss: 5344331.2655, Eval acc: 0.8063\n",
      "Epoch: 76, Train loss: 100610813.9142, Train acc: 0.8059, Eval loss: 4436895.9037, Eval acc: 0.8041\n",
      "Epoch: 77, Train loss: 99028264.7303, Train acc: 0.8074, Eval loss: 5676919.0258, Eval acc: 0.8064\n",
      "Epoch: 78, Train loss: 98037950.1284, Train acc: 0.8066, Eval loss: 6184805.2958, Eval acc: 0.8053\n",
      "Epoch: 79, Train loss: 98381871.4043, Train acc: 0.8074, Eval loss: 5940746.4321, Eval acc: 0.8055\n",
      "Epoch: 80, Train loss: 100937840.2998, Train acc: 0.8073, Eval loss: 5972538.5831, Eval acc: 0.8060\n",
      "Epoch: 81, Train loss: 97941828.9742, Train acc: 0.8073, Eval loss: 4962721.1072, Eval acc: 0.8059\n",
      "Epoch: 82, Train loss: 104393605.3173, Train acc: 0.8072, Eval loss: 6336393.8103, Eval acc: 0.8068\n",
      "Epoch: 83, Train loss: 99076422.6888, Train acc: 0.8070, Eval loss: 5754783.8089, Eval acc: 0.8061\n",
      "Epoch: 84, Train loss: 100032715.4461, Train acc: 0.8071, Eval loss: 5850499.0524, Eval acc: 0.8058\n",
      "Epoch: 85, Train loss: 94025465.9957, Train acc: 0.8072, Eval loss: 5630478.8363, Eval acc: 0.8053\n",
      "Epoch: 86, Train loss: 111412882.1202, Train acc: 0.8072, Eval loss: 5313877.1692, Eval acc: 0.8056\n",
      "Epoch: 87, Train loss: 97404214.5035, Train acc: 0.8067, Eval loss: 5528646.2093, Eval acc: 0.8056\n",
      "Epoch: 88, Train loss: 97381332.4234, Train acc: 0.8068, Eval loss: 5264233.3029, Eval acc: 0.8044\n",
      "Epoch: 89, Train loss: 97876924.3672, Train acc: 0.8075, Eval loss: 5877829.6477, Eval acc: 0.8054\n",
      "Epoch: 90, Train loss: 101589388.0893, Train acc: 0.8068, Eval loss: 5525416.7183, Eval acc: 0.8050\n",
      "Epoch: 91, Train loss: 102147564.5830, Train acc: 0.8069, Eval loss: 6292222.8306, Eval acc: 0.8051\n",
      "Epoch: 92, Train loss: 96989944.2211, Train acc: 0.8063, Eval loss: 6367085.7771, Eval acc: 0.8055\n",
      "Epoch: 93, Train loss: 98381630.7397, Train acc: 0.8076, Eval loss: 5414639.9691, Eval acc: 0.8053\n",
      "Epoch: 94, Train loss: 92116739.1232, Train acc: 0.8061, Eval loss: 5955294.7465, Eval acc: 0.8053\n",
      "Epoch: 95, Train loss: 94878339.4637, Train acc: 0.8077, Eval loss: 5794947.6799, Eval acc: 0.8059\n",
      "Epoch: 96, Train loss: 100264569.0869, Train acc: 0.8069, Eval loss: 5657731.7259, Eval acc: 0.8048\n",
      "Epoch: 97, Train loss: 107915839.9869, Train acc: 0.8054, Eval loss: 5506870.8835, Eval acc: 0.8035\n",
      "Epoch: 98, Train loss: 99050183.4764, Train acc: 0.8073, Eval loss: 5564546.3272, Eval acc: 0.8052\n",
      "Epoch: 99, Train loss: 99685030.1287, Train acc: 0.8075, Eval loss: 6032460.9396, Eval acc: 0.8055\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    mask = y_pred > 0\n",
    "    y_pred = np.where(mask, y_pred, 1e-9)\n",
    "    return -np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "\n",
    "# np.random.seed(42)\n",
    "# x_train = np.random.randn(1000, 300)\n",
    "# y_train = np.random.randint(0, 4, size=(1000,))\n",
    "# y_train = np.eye(4)[y_train]\n",
    "# x_val = np.random.randn(100, 300)\n",
    "# y_val = np.random.randint(0, 4, size=(100,))\n",
    "# y_val = np.eye(4)[y_val]\n",
    "\n",
    "W2 = np.random.randn(300, 4)\n",
    "eta = 0.001\n",
    "n_epochs = 100\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "train_acc = []\n",
    "eval_acc = []\n",
    "\n",
    "# create an empty dictionary to store checkpoints\n",
    "checkpoints = {}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    indices = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    # compute loss and accuracy on training set\n",
    "    train_probs = softmax(x_train.dot(W2))\n",
    "    train_loss.append(cross_entropy_loss(y_train, train_probs))\n",
    "    train_pred = np.argmax(train_probs, axis=1)\n",
    "    train_acc.append(np.mean(train_pred == np.argmax(y_train, axis=1)))\n",
    "    # compute loss and accuracy on validation set\n",
    "    eval_probs = softmax(x_val.dot(W2))\n",
    "    eval_loss.append(cross_entropy_loss(y_val, eval_probs))\n",
    "    eval_pred = np.argmax(eval_probs, axis=1)\n",
    "    eval_acc.append(np.mean(eval_pred == np.argmax(y_val, axis=1)))\n",
    "    # update the parameters\n",
    "    for i in range(x_train.shape[0]):\n",
    "        y_hat = softmax(np.dot(x_train[i], W2))\n",
    "        dW = np.outer(x_train[i], y_hat - y_train[i])\n",
    "        W2 = W2 - eta * dW\n",
    "    # store the checkpoint\n",
    "    checkpoints[epoch] = {'W2': W2, 'eta': eta}\n",
    "    with open('checkpoints.pkl', 'wb') as f:\n",
    "        pickle.dump(checkpoints, f)\n",
    "    # print progress\n",
    "    print(\"Epoch: %d, Train loss: %.4f, Train acc: %.4f, Eval loss: %.4f, Eval acc: %.4f\" % (\n",
    "        epoch, train_loss[-1], train_acc[-1], eval_loss[-1], eval_acc[-1]))\n",
    "\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(eval_loss, label='eval')\n",
    "plt.plot(train_acc, label='train acc')\n",
    "plt.plot(eval_acc, label='eval acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('value')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 77. Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 1...\n",
      "Epoch: 0, Train loss: 102247614.8134, Train acc: 0.7691, Eval loss: 6213321.2580, Eval acc: 0.7673\n",
      "Epoch: 1, Train loss: 84984088.8856, Train acc: 0.7981, Eval loss: 6486171.9928, Eval acc: 0.7965\n",
      "Epoch: 2, Train loss: 78081669.7052, Train acc: 0.8042, Eval loss: 6420645.9790, Eval acc: 0.8024\n",
      "Epoch: 3, Train loss: 74493172.4215, Train acc: 0.8062, Eval loss: 6224736.1230, Eval acc: 0.8043\n",
      "Epoch: 4, Train loss: 74292170.3079, Train acc: 0.8067, Eval loss: 6397599.0756, Eval acc: 0.8051\n",
      "Epoch: 5, Train loss: 66743733.0681, Train acc: 0.8075, Eval loss: 5842201.2155, Eval acc: 0.8063\n",
      "Epoch: 6, Train loss: 75716384.8349, Train acc: 0.8075, Eval loss: 6693166.1294, Eval acc: 0.8056\n",
      "Epoch: 7, Train loss: 68001205.1707, Train acc: 0.8075, Eval loss: 6227398.8458, Eval acc: 0.8056\n",
      "Epoch: 8, Train loss: 67740316.0190, Train acc: 0.8073, Eval loss: 5879032.0132, Eval acc: 0.8057\n",
      "Epoch: 9, Train loss: 53510867.0146, Train acc: 0.8064, Eval loss: 4738392.9797, Eval acc: 0.8046\n",
      "Epoch: 10, Train loss: 62487978.9161, Train acc: 0.8037, Eval loss: 5487004.2569, Eval acc: 0.8031\n",
      "Epoch: 11, Train loss: 75431531.0200, Train acc: 0.8071, Eval loss: 6705038.9218, Eval acc: 0.8059\n",
      "Epoch: 12, Train loss: 80971282.9819, Train acc: 0.8071, Eval loss: 7090740.6779, Eval acc: 0.8042\n",
      "Epoch: 13, Train loss: 68781024.6788, Train acc: 0.8070, Eval loss: 6096035.2819, Eval acc: 0.8046\n",
      "Epoch: 14, Train loss: 63318623.2750, Train acc: 0.8052, Eval loss: 5964237.3836, Eval acc: 0.8048\n",
      "Epoch: 15, Train loss: 62923699.8542, Train acc: 0.8076, Eval loss: 5612019.3022, Eval acc: 0.8064\n",
      "Epoch: 16, Train loss: 71668895.0122, Train acc: 0.8074, Eval loss: 6423529.3959, Eval acc: 0.8056\n",
      "Epoch: 17, Train loss: 68937540.9876, Train acc: 0.8062, Eval loss: 6106740.4202, Eval acc: 0.8046\n",
      "Epoch: 18, Train loss: 68015904.9750, Train acc: 0.8072, Eval loss: 6176499.9115, Eval acc: 0.8066\n",
      "Epoch: 19, Train loss: 72192575.8446, Train acc: 0.8075, Eval loss: 6618751.3841, Eval acc: 0.8062\n",
      "Epoch: 20, Train loss: 59026882.1542, Train acc: 0.8070, Eval loss: 5514207.9024, Eval acc: 0.8065\n",
      "Epoch: 21, Train loss: 76271074.8794, Train acc: 0.8071, Eval loss: 6695696.0470, Eval acc: 0.8051\n",
      "Epoch: 22, Train loss: 65560545.4147, Train acc: 0.8067, Eval loss: 6066365.2638, Eval acc: 0.8051\n",
      "Epoch: 23, Train loss: 75353023.9513, Train acc: 0.8072, Eval loss: 6751161.9016, Eval acc: 0.8058\n",
      "Epoch: 24, Train loss: 61591995.2142, Train acc: 0.8070, Eval loss: 5572713.4800, Eval acc: 0.8051\n",
      "Epoch: 25, Train loss: 67721983.3713, Train acc: 0.8075, Eval loss: 5926600.7053, Eval acc: 0.8059\n",
      "Epoch: 26, Train loss: 70073095.0380, Train acc: 0.8069, Eval loss: 6319392.3736, Eval acc: 0.8049\n",
      "Epoch: 27, Train loss: 70392314.1612, Train acc: 0.8071, Eval loss: 6250453.1780, Eval acc: 0.8049\n",
      "Epoch: 28, Train loss: 64689366.7823, Train acc: 0.8079, Eval loss: 5845912.6206, Eval acc: 0.8071\n",
      "Epoch: 29, Train loss: 62166866.9460, Train acc: 0.8071, Eval loss: 5418831.6403, Eval acc: 0.8057\n",
      "Epoch: 30, Train loss: 61036898.2965, Train acc: 0.8071, Eval loss: 5572201.2310, Eval acc: 0.8053\n",
      "Epoch: 31, Train loss: 62472470.1730, Train acc: 0.8071, Eval loss: 5403015.1729, Eval acc: 0.8062\n",
      "Epoch: 32, Train loss: 78820465.0837, Train acc: 0.8069, Eval loss: 7074330.2011, Eval acc: 0.8066\n",
      "Epoch: 33, Train loss: 71191840.5485, Train acc: 0.8063, Eval loss: 6351360.9985, Eval acc: 0.8049\n",
      "Epoch: 34, Train loss: 68563898.8847, Train acc: 0.8079, Eval loss: 5951486.0188, Eval acc: 0.8057\n",
      "Epoch: 35, Train loss: 63235909.0108, Train acc: 0.8071, Eval loss: 5445270.7559, Eval acc: 0.8056\n",
      "Epoch: 36, Train loss: 79196660.9417, Train acc: 0.8075, Eval loss: 6984532.6512, Eval acc: 0.8061\n",
      "Epoch: 37, Train loss: 72260273.2501, Train acc: 0.8074, Eval loss: 6489143.9940, Eval acc: 0.8062\n",
      "Epoch: 38, Train loss: 77627772.2102, Train acc: 0.8076, Eval loss: 6952098.5108, Eval acc: 0.8061\n",
      "Epoch: 39, Train loss: 73624684.3523, Train acc: 0.8073, Eval loss: 6614011.8112, Eval acc: 0.8064\n",
      "Epoch: 40, Train loss: 64972806.3202, Train acc: 0.8071, Eval loss: 5791242.8293, Eval acc: 0.8053\n",
      "Epoch: 41, Train loss: 65959320.6185, Train acc: 0.8067, Eval loss: 5774057.4933, Eval acc: 0.8054\n",
      "Epoch: 42, Train loss: 62849107.5546, Train acc: 0.8064, Eval loss: 5662475.4621, Eval acc: 0.8045\n",
      "Epoch: 43, Train loss: 67041458.3508, Train acc: 0.8053, Eval loss: 6042830.6877, Eval acc: 0.8026\n",
      "Epoch: 44, Train loss: 71684094.2069, Train acc: 0.8074, Eval loss: 6441648.2849, Eval acc: 0.8062\n",
      "Epoch: 45, Train loss: 67965946.7847, Train acc: 0.8076, Eval loss: 6061855.7858, Eval acc: 0.8052\n",
      "Epoch: 46, Train loss: 70975282.4935, Train acc: 0.8068, Eval loss: 6513879.0861, Eval acc: 0.8065\n",
      "Epoch: 47, Train loss: 78270503.0269, Train acc: 0.8069, Eval loss: 6669431.0864, Eval acc: 0.8061\n",
      "Epoch: 48, Train loss: 69044741.1274, Train acc: 0.8071, Eval loss: 6152940.3719, Eval acc: 0.8054\n",
      "Epoch: 49, Train loss: 64658352.6025, Train acc: 0.8075, Eval loss: 5848529.1700, Eval acc: 0.8065\n",
      "Epoch: 50, Train loss: 68023561.1262, Train acc: 0.8070, Eval loss: 5908866.1910, Eval acc: 0.8065\n",
      "Epoch: 51, Train loss: 70081451.6905, Train acc: 0.8069, Eval loss: 6195134.7330, Eval acc: 0.8057\n",
      "Epoch: 52, Train loss: 79114170.8225, Train acc: 0.8074, Eval loss: 6803477.5423, Eval acc: 0.8054\n",
      "Epoch: 53, Train loss: 63065993.2894, Train acc: 0.8071, Eval loss: 5463462.0942, Eval acc: 0.8059\n",
      "Epoch: 54, Train loss: 60380302.6119, Train acc: 0.8066, Eval loss: 5491131.7722, Eval acc: 0.8043\n",
      "Epoch: 55, Train loss: 72601666.1189, Train acc: 0.8074, Eval loss: 6423329.3809, Eval acc: 0.8061\n",
      "Epoch: 56, Train loss: 68836085.6451, Train acc: 0.8064, Eval loss: 6282237.2986, Eval acc: 0.8054\n",
      "Epoch: 57, Train loss: 77072302.4189, Train acc: 0.8072, Eval loss: 6833517.6625, Eval acc: 0.8057\n",
      "Epoch: 58, Train loss: 63901045.9208, Train acc: 0.8074, Eval loss: 5653422.8965, Eval acc: 0.8064\n",
      "Epoch: 59, Train loss: 69900355.5085, Train acc: 0.8068, Eval loss: 6291483.3867, Eval acc: 0.8055\n",
      "Epoch: 60, Train loss: 65630916.6556, Train acc: 0.8066, Eval loss: 5865171.5259, Eval acc: 0.8048\n",
      "Epoch: 61, Train loss: 73172400.6178, Train acc: 0.8079, Eval loss: 6642713.2382, Eval acc: 0.8065\n",
      "Epoch: 62, Train loss: 72751748.8643, Train acc: 0.8074, Eval loss: 6600299.4558, Eval acc: 0.8064\n",
      "Epoch: 63, Train loss: 63904872.8069, Train acc: 0.8067, Eval loss: 5798744.8294, Eval acc: 0.8049\n",
      "Epoch: 64, Train loss: 70526573.4553, Train acc: 0.8077, Eval loss: 6189126.1381, Eval acc: 0.8054\n",
      "Epoch: 65, Train loss: 63999672.3516, Train acc: 0.8071, Eval loss: 5484043.8997, Eval acc: 0.8059\n",
      "Epoch: 66, Train loss: 75360615.8652, Train acc: 0.8079, Eval loss: 6755438.5621, Eval acc: 0.8063\n",
      "Epoch: 67, Train loss: 67170897.4299, Train acc: 0.8069, Eval loss: 5818839.4234, Eval acc: 0.8066\n",
      "Epoch: 68, Train loss: 82843459.7136, Train acc: 0.8075, Eval loss: 7472290.5717, Eval acc: 0.8054\n",
      "Epoch: 69, Train loss: 72438279.1241, Train acc: 0.8077, Eval loss: 6534262.0723, Eval acc: 0.8060\n",
      "Epoch: 70, Train loss: 78407365.9459, Train acc: 0.8070, Eval loss: 6986812.3446, Eval acc: 0.8060\n",
      "Epoch: 71, Train loss: 64644460.9349, Train acc: 0.8062, Eval loss: 5743976.3355, Eval acc: 0.8047\n",
      "Epoch: 72, Train loss: 66566431.4158, Train acc: 0.8074, Eval loss: 5898756.1902, Eval acc: 0.8058\n",
      "Epoch: 73, Train loss: 62967819.4281, Train acc: 0.8071, Eval loss: 5644230.8465, Eval acc: 0.8056\n",
      "Epoch: 74, Train loss: 65885392.4217, Train acc: 0.8060, Eval loss: 5886449.3839, Eval acc: 0.8040\n",
      "Epoch: 75, Train loss: 69702691.7142, Train acc: 0.8066, Eval loss: 6340973.5856, Eval acc: 0.8042\n",
      "Epoch: 76, Train loss: 66879970.9544, Train acc: 0.8077, Eval loss: 6197089.5263, Eval acc: 0.8061\n",
      "Epoch: 77, Train loss: 68218805.7571, Train acc: 0.8074, Eval loss: 6212432.0162, Eval acc: 0.8074\n",
      "Epoch: 78, Train loss: 71259641.2317, Train acc: 0.8067, Eval loss: 6058980.3106, Eval acc: 0.8051\n",
      "Epoch: 79, Train loss: 59248909.6940, Train acc: 0.8077, Eval loss: 5321992.3675, Eval acc: 0.8060\n",
      "Epoch: 80, Train loss: 67173361.2542, Train acc: 0.8071, Eval loss: 5898252.3657, Eval acc: 0.8059\n",
      "Epoch: 81, Train loss: 68475782.4469, Train acc: 0.8077, Eval loss: 6082409.5937, Eval acc: 0.8066\n",
      "Epoch: 82, Train loss: 71749412.5264, Train acc: 0.8070, Eval loss: 6383349.4347, Eval acc: 0.8052\n",
      "Epoch: 83, Train loss: 64821795.2445, Train acc: 0.8066, Eval loss: 5751401.9002, Eval acc: 0.8049\n",
      "Epoch: 84, Train loss: 76893045.8191, Train acc: 0.8075, Eval loss: 6603152.1839, Eval acc: 0.8048\n",
      "Epoch: 85, Train loss: 70098412.0026, Train acc: 0.8056, Eval loss: 6036230.4948, Eval acc: 0.8041\n",
      "Epoch: 86, Train loss: 63827656.3437, Train acc: 0.8063, Eval loss: 5562435.9410, Eval acc: 0.8053\n",
      "Epoch: 87, Train loss: 69467372.8445, Train acc: 0.8072, Eval loss: 6114719.3708, Eval acc: 0.8058\n",
      "Epoch: 88, Train loss: 68253127.2292, Train acc: 0.8076, Eval loss: 6208880.6363, Eval acc: 0.8062\n",
      "Epoch: 89, Train loss: 60910336.7491, Train acc: 0.8066, Eval loss: 5420865.3033, Eval acc: 0.8049\n",
      "Epoch: 90, Train loss: 65371820.5171, Train acc: 0.8072, Eval loss: 5611112.4850, Eval acc: 0.8071\n",
      "Epoch: 91, Train loss: 72157355.5092, Train acc: 0.8056, Eval loss: 6242188.7267, Eval acc: 0.8040\n",
      "Epoch: 92, Train loss: 54159082.8259, Train acc: 0.8059, Eval loss: 4675269.6071, Eval acc: 0.8037\n",
      "Epoch: 93, Train loss: 71002736.7326, Train acc: 0.8071, Eval loss: 6376997.0105, Eval acc: 0.8054\n",
      "Epoch: 94, Train loss: 71139911.1319, Train acc: 0.8076, Eval loss: 6579782.6705, Eval acc: 0.8071\n",
      "Epoch: 95, Train loss: 67030627.1012, Train acc: 0.8076, Eval loss: 5963665.9905, Eval acc: 0.8068\n",
      "Epoch: 96, Train loss: 73428986.3664, Train acc: 0.8078, Eval loss: 6340725.0447, Eval acc: 0.8062\n",
      "Epoch: 97, Train loss: 76556153.8751, Train acc: 0.8072, Eval loss: 6590205.0755, Eval acc: 0.8060\n",
      "Epoch: 98, Train loss: 65598364.3679, Train acc: 0.8075, Eval loss: 5866739.5614, Eval acc: 0.8052\n",
      "Epoch: 99, Train loss: 70376292.1180, Train acc: 0.8076, Eval loss: 6212621.6288, Eval acc: 0.8062\n",
      "Training with batch size 1 took 755.11 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dotha\\AppData\\Local\\Temp\\ipykernel_17096\\3837361428.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "C:\\Users\\dotha\\AppData\\Local\\Temp\\ipykernel_17096\\3837361428.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 2 took 416.81 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 4...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 4 took 234.45 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 8...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 8 took 154.10 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 16...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 16 took 114.89 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 32...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 32 took 91.99 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 64...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 64 took 79.41 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAERCAYAAABxZrw0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY8klEQVR4nO3df3RV5Z3v8fenEAER+RmtlWpih5FfkiAhRbFeRwoLtbVSp0JbZ6zLitXK2NvRKR27rnbVjrbaua29WBt/VHtVCoU6VJc6U6iUjhVLsIwiMFIUxnRQIr/phWro9/5xDhiUQBLOzkme83mtdVbO2Xuf/Xwftn6y85x9nq2IwMzM0vO+YhdgZmbZcMCbmSXKAW9mligHvJlZohzwZmaJcsCbmSWq0wW8pPslbZK0spXbXyJplaSXJD2SdX1mZl2FOtt18JLOBnYBP46IkYfZdggwFzg3IrZKOi4iNnVEnWZmnV2nO4OPiCXAlubLJH1I0lOSlkv6taSh+VVXArMiYmv+vQ53M7O8ThfwLagDZkTEGOB64K788r8E/lLSM5KWSppctArNzDqZ7sUu4HAkHQOcCfxU0r7FPfI/uwNDgHOAwcASSadFxLYOLtPMrNPp9AFP7q+MbRFRfZB1DcBzEfE28Kqkl8kF/rIOrM/MrFPq9EM0EbGDXHh/CkA5VfnV/0Lu7B1Jg8gN2bxShDLNzDqdThfwkmYDzwKnSmqQdAXwWeAKSf8BvAR8Ir/5vwKbJa0CngZuiIjNxajbzKyz6XSXSZqZWWF0ujN4MzMrjE71IeugQYOioqKi2GWYmXUZy5cvfzMiyg+2rlMFfEVFBfX19cUuw8ysy5C0oaV1HqIxM0uUA97MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRHWq6+Db6+uPvcSq/95R7DLMzNpl+AeO5aaPjyj4fn0Gb2aWqCTO4LP4zWdm1tX5DN7MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRGUa8JL6SZonaY2k1ZLOyLI9MzN7R9bzwX8PeCoi/lrSUcDRGbdnZmZ5mQW8pL7A2cDnACLiLeCtrNozM7MDZTlEUwk0Aj+S9DtJ90rq/e6NJE2XVC+pvrGxMcNyzMxKS5YB3x04HfhBRIwG/gjMfPdGEVEXETURUVNeXp5hOWZmpSXLgG8AGiLiufzreeQC38zMOkBmAR8RrwOvSTo1v2gCsCqr9szM7EBZX0UzA3g4fwXNK8DlGbdnZmZ5mQZ8RKwAarJsw8zMDs7fZDUzS5QD3swsUQ54M7NEOeDNzBLlgDczS5QD3swsUQ54M7NEOeDNzBLlgDczS5QD3swsUQ54M7NEOeDNzBLlgDczS5QD3swsUQ54M7NEOeDNzBLlgDczS5QD3swsUQ54M7NEOeDNzBLlgDczS1T3LHcuaT2wE9gLNEVETZbtmZnZOzIN+Ly/iog3O6AdMzNrxkM0ZmaJyjrgA/g3ScslTT/YBpKmS6qXVN/Y2JhxOWZmpSPrgD8rIk4HzgO+KOnsd28QEXURURMRNeXl5RmXY2ZWOjIN+Ij4Q/7nJuBRoDbL9szM7B2ZBbyk3pL67HsOTAJWZtWemZkdKMuraI4HHpW0r51HIuKpDNszM7NmMgv4iHgFqMpq/2Zmdmi+TNLMLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEOeDOzRDngzcwS5YA3M0uUA97MLFEdcdNtM7P93n77bRoaGtizZ0+xS+lSevbsyeDBgykrK2v1exzwZtahGhoa6NOnDxUVFeTvF2GHERFs3ryZhoYGKisrW/0+D9GYWYfas2cPAwcOdLi3gSQGDhzY5r96HPBm1uEc7m3Xnn8zB7yZlZRt27Zx1113tfl9559/Ptu2bSt8QRlywJtZSWkp4Juamg75vieeeIJ+/fplVFU2/CGrmZWUmTNnsm7dOqqrqykrK6Nnz57079+fNWvW8PLLL3PRRRfx2muvsWfPHq677jqmT58OQEVFBfX19ezatYvzzjuPs846i9/85jeceOKJLFiwgF69ehW5Z+/lgDezovn6Yy+x6r93FHSfwz9wLDd9fESL62+77TZWrlzJihUrWLx4MRdccAErV67cf3XK/fffz4ABA9i9ezdjx47l4osvZuDAgQfsY+3atcyePZt77rmHSy65hPnz53PppZcWtB+FkPkQjaRukn4n6fGs2zIza6va2toDLj288847qaqqYty4cbz22musXbv2Pe+prKykuroagDFjxrB+/foOqrZtOuIM/jpgNXBsB7RlZl3Ioc60O0rv3r33P1+8eDELFy7k2Wef5eijj+acc8456KWJPXr02P+8W7du7N69u0NqbatMz+AlDQYuAO7Nsh0zs9bq06cPO3fuPOi67du3079/f44++mjWrFnD0qVLO7i6wsr6DP67wD8AfVraQNJ0YDrASSedlHE5ZlbqBg4cyPjx4xk5ciS9evXi+OOP379u8uTJ3H333QwbNoxTTz2VcePGFbHSI6eIyGbH0seA8yPiGknnANdHxMcO9Z6ampqor6/PpB4z6xxWr17NsGHDil1Gl3SwfztJyyOi5mDbZzlEMx64UNJ64CfAuZIeyrA9MzNrJrOAj4ivRsTgiKgApgG/jIjOdx2RmVmi/E1WM7NEdcgXnSJiMbC4I9oyM7Mcn8GbmSXKAW9mligHvJlZO1RUVPDmm28Wu4xDcsCbmSXqsAEv6XhJ90l6Mv96uKQrsi/NzCwbDz30ELW1tVRXV3PVVVcxa9Ysbrjhhv3rH3jgAa699loALrroIsaMGcOIESOoq6srVsnt0pqraB4AfgTcmH/9MjAHuC+jmsysVDw5E15/sbD7fP9pcN5tLa5evXo1c+bM4ZlnnqGsrIxrrrmGY445hkcffZTbb78dgDlz5nDjjbnIa830wZ1VawJ+UETMlfRVgIhokrQ347rMzDKxaNEili9fztixYwHYvXs3xx13HKeccgpLly5lyJAhrFmzhvHjxwO56YMfffRRgP3TB6cU8H+UNBAIAEnjgO2ZVmVmpeEQZ9pZiQguu+wybr311gOW33///cydO5ehQ4cyZcoUJLV6+uDOqjUfsn4Z+DnwIUnPAD8GZmRalZlZRiZMmMC8efPYtGkTAFu2bGHDhg1MmTKFBQsWMHv2bKZNmwZ0/emDD3sGHxHPS/ofwKmAgP+MiLczr8zMLAPDhw/nlltuYdKkSfz5z3+mrKyMWbNmcfLJJzNs2DBWrVpFbW0t0PWnDz7sdMGS/vZgyyPix4UuxtMFm6XP0wW3X1unC27NGPzYZs97AhOA58kN1ZiZWSfVmiGaA8bbJfUjN7+7mZl1Yu35JusfgcrDbmVmZkV12DN4SY+Rv0SS3C+E4cDcLIsyM7Mj15ox+DuaPW8CNkREQ0b1mJlZgbRmDP5XHVGImZkVVotj8JJ2StpxkMdOSTs6skgzs0LZtm0bd911V7vee/7557Nt27bCFpShFgM+IvpExLEHefSJiGM7skgzs0I5VMA3NTUd8r1PPPEE/fr1y6CqbLT6KhpJx0k6ad8jy6LMzLIyc+ZM1q1bR3V1NTfccAOLFy/mIx/5CBdeeCHDhw8HWp4ieN9NPtavX8+wYcO48sorGTFiBJMmTWL37t3vaeuxxx7jwx/+MKNHj+ajH/0ob7zxBgC7du3i8ssv57TTTmPUqFHMnz8fgKeeeorTTz+dqqoqJkyYcMR9bc1VNBcC3wE+AGwCTgZWAyMO876ewBKgR76deRFx05EWbGbp+NZvv8WaLWsKus+hA4byldqvtLj+tttuY+XKlaxYsQKAxYsX8/zzz7Ny5UoqK3NXgLdmiuC1a9cye/Zs7rnnHi655BLmz5/PpZdeesA2Z511FkuXLkUS9957L9/+9rf5zne+wze+8Q369u3Liy/mpkreunUrjY2NXHnllSxZsoTKykq2bNlyxP8WrbmK5hvAOGBhRIyW9FfApYd5D8CfgHMjYpekMuDfJT0ZEV1rth4zS15tbe3+cIfWTRFcWVlJdXU1AGPGjGH9+vXv2W9DQwNTp05l48aNvPXWW/vbWLhwIT/5yTvfF+3fvz+PPfYYZ5999v5tBgwYcMT9ak3Avx0RmyW9T9L7IuJpSd893JsiN8nNrvzLsvzj0BPfmFlJOdSZdkfq3bv3/uetnSK4R48e+59369btoEM0M2bM4Mtf/jIXXnghixcv5uabb86k/pa0Zgx+m6RjgF8DD0v6Hrlvsx6WpG6SVpAb2vlFRDzX7krNzAqgT58+7Ny5s8X1hZwiePv27Zx44okAPPjgg/uXT5w4kVmzZu1/vXXrVsaNG8eSJUt49dVXAQoyRNOagH8a6AtcBzwFrAM+3pqdR8TeiKgGBgO1kka+extJ0yXVS6pvbGxsdeFmZu0xcOBAxo8fz8iRIw+4D+s+kydPpqmpiWHDhjFz5swjmiL45ptv5lOf+hRjxoxh0KBB+5d/7WtfY+vWrYwcOZKqqiqefvppysvLqaur45Of/CRVVVVMnTq13e3u05rpgm8CLgG2kLsX608j4o02NyT9L+D/RcQdLW3j6YLN0ufpgtuvrdMFH/YMPiK+HhEjgC8CJwC/krTwcO+TVJ6feRJJvYCJQGE/Ljczsxa15kPWfTYBrwObgeNasf0JwIOSupH7RTI3Ih5ve4lmZtYerbkO/hpyQzTlwE+BKyNi1eHeFxEvAKOPuEIzM2uX1pzBfxD4UkSsyLgWMzMroNbMJvnVjijEzMwKqz13dDIzsy7AAW9m1k77Jh/rrBzwZmaJcsCbWcl56KGHqK2tpbq6mquuuoq9e/dy9913H/DN1gceeIBrr70WaHn64JZcffXV1NTUMGLECG666Z1JdJctW8aZZ55JVVUVtbW17Ny5k71793L99dczcuRIRo0axfe///2C9bMt18GbmRXU6//0T/xpdWG//9hj2FDe/4//2OL61atXM2fOHJ555hnKysq45pprePjhh7n44os544wzuP322wGYM2cON954I9C66YOb++Y3v8mAAQPYu3cvEyZM4IUXXmDo0KFMnTqVOXPmMHbsWHbs2EGvXr2oq6tj/fr1rFixgu7duxdkDpp9HPBmVlIWLVrE8uXLGTt2LAC7d+/muOOOo7y8nFNOOYWlS5cyZMgQ1qxZw/jx44HWTR/c3Ny5c6mrq6OpqYmNGzeyatUqJHHCCSfsb/fYY3M3xlu4cCFf+MIX6N49F8eFmCZ4Hwe8mRXNoc60sxIRXHbZZdx6663vWTdt2jTmzp3L0KFDmTJlCpJaPX3wPq+++ip33HEHy5Yto3///nzuc5875PZZ8hi8mZWUCRMmMG/ePDZt2gTkpuXdsGEDAFOmTGHBggXMnj2badOmAW2fPnjHjh307t2bvn378sYbb/Dkk08CcOqpp7Jx40aWLVsGwM6dO2lqamLixIn88Ic/3H8/2EIO0TjgzaykDB8+nFtuuYVJkyYxatQoJk6cyMaNG4HcnZWGDRvGhg0bqK2tBdo+fXBVVRWjR49m6NChfOYzn9k/zHPUUUcxZ84cZsyYQVVVFRMnTmTPnj18/vOf56STTmLUqFFUVVXxyCOPFKyvh50uuCN5umCz9Hm64PYr+HTBZmbWNTngzcwS5YA3M0uUA97MOlxn+uyvq2jPv5kD3sw6VM+ePdm8ebNDvg0igs2bN9OzZ882vc9fdDKzDjV48GAaGhpobGwsdildSs+ePRk8eHCb3uOAN7MOVVZWRmVlZbHLKAkeojEzS5QD3swsUZkFvKQPSnpa0ipJL0m6Lqu2zMzsvbIcg28C/j4inpfUB1gu6RcRsSrDNs3MLC+zM/iI2BgRz+ef7wRWAydm1Z6ZmR2oQ8bgJVUAo4HnDrJuuqR6SfW+bMrMrHAyD3hJxwDzgS9FxI53r4+IuoioiYia8vLyrMsxMysZmQa8pDJy4f5wRPwsy7bMzOxAWV5FI+A+YHVE/HNW7ZiZ2cFleQY/Hvgb4FxJK/KP8zNsz8zMmsnsMsmI+HdAWe3fzMwOzd9kNTNLlAPezCxRDngzs0Q54M3MEuWANzNLlAPezCxRDngzs0Q54M3MEuWANzNLlAPezCxRDngzs0Q54M3MEuWANzNLlAPezCxRDngzs0Q54M3MEuWANzNLlAPezCxRDngzs0Q54M3MEuWANzNLVGYBL+l+SZskrcyqDTMza1mWZ/APAJMz3L+ZmR1CZgEfEUuALVnt38zMDq3oY/CSpkuql1Tf2NhY7HLMzJJR9ICPiLqIqImImvLy8mKXY2aWjKIHvJmZZcMBb2aWqO5Z7VjSbOAcYJCkBuCmiLgvk8aenAmvv5jJrs3MMvf+0+C82wq+28wCPiI+ndW+zczs8DIL+A6VwW8+M7OuzmPwZmaJcsCbmSXKAW9mligHvJlZohzwZmaJcsCbmSXKAW9mligHvJlZohzwZmaJcsCbmSXKAW9mligHvJlZohzwZmaJcsCbmSXKAW9mligHvJlZohzwZmaJcsCbmSXKAW9mligHvJlZojINeEmTJf2npN9LmpllW2ZmdqDMAl5SN2AWcB4wHPi0pOFZtWdmZgfqnuG+a4HfR8QrAJJ+AnwCWFXohh7/u09Stq6h0Ls1M+sQb39oMB+782cF32+WQzQnAq81e92QX3YASdMl1Uuqb2xszLAcM7PSkuUZfKtERB1QB1BTUxPt2UcWv/nMzLq6LM/g/wB8sNnrwfllZmbWAbIM+GXAEEmVko4CpgE/z7A9MzNrJrMhmohoknQt8K9AN+D+iHgpq/bMzOxAmY7BR8QTwBNZtmFmZgfnb7KamSXKAW9mligHvJlZohzwZmaJUkS7vluUCUmNwIZ2vn0Q8GYBy+kKSrHPUJr9LsU+Q2n2u619Pjkiyg+2olMF/JGQVB8RNcWuoyOVYp+hNPtdin2G0ux3IfvsIRozs0Q54M3MEpVSwNcVu4AiKMU+Q2n2uxT7DKXZ74L1OZkxeDMzO1BKZ/BmZtaMA97MLFFdPuBL5cbekj4o6WlJqyS9JOm6/PIBkn4haW3+Z/9i11pokrpJ+p2kx/OvKyU9lz/mc/LTUSdFUj9J8yStkbRa0hmpH2tJ/zP/3/ZKSbMl9UzxWEu6X9ImSSubLTvosVXOnfn+vyDp9La01aUDvsRu7N0E/H1EDAfGAV/M93UmsCgihgCL8q9Tcx2wutnrbwH/OyL+AtgKXFGUqrL1PeCpiBgKVJHrf7LHWtKJwN8BNRExktwU49NI81g/AEx+17KWju15wJD8Yzrwg7Y01KUDnmY39o6It4B9N/ZOTkRsjIjn8893kvsf/kRy/X0wv9mDwEVFKTAjkgYDFwD35l8LOBeYl98kxT73Bc4G7gOIiLciYhuJH2ty05f3ktQdOBrYSILHOiKWAFvetbilY/sJ4MeRsxToJ+mE1rbV1QO+VTf2To2kCmA08BxwfERszK96HTi+WHVl5LvAPwB/zr8eCGyLiKb86xSPeSXQCPwoPzR1r6TeJHysI+IPwB3Af5EL9u3ActI/1vu0dGyPKOO6esCXHEnHAPOBL0XEjubrInfNazLXvUr6GLApIpYXu5YO1h04HfhBRIwG/si7hmMSPNb9yZ2tVgIfAHrz3mGMklDIY9vVA76kbuwtqYxcuD8cET/LL35j359s+Z+bilVfBsYDF0paT2747VxyY9P98n/GQ5rHvAFoiIjn8q/nkQv8lI/1R4FXI6IxIt4Gfkbu+Kd+rPdp6dgeUcZ19YAvmRt758ee7wNWR8Q/N1v1c+Cy/PPLgAUdXVtWIuKrETE4IirIHdtfRsRngaeBv85vllSfASLideA1SafmF00AVpHwsSY3NDNO0tH5/9b39TnpY91MS8f258Df5q+mGQdsbzaUc3gR0aUfwPnAy8A64MZi15NhP88i92fbC8CK/ON8cmPSi4C1wEJgQLFrzaj/5wCP55+fAvwW+D3wU6BHsevLoL/VQH3+eP8L0D/1Yw18HVgDrAT+L9AjxWMNzCb3OcPb5P5au6KlYwuI3JWC64AXyV1l1Oq2PFWBmVmiuvoQjZmZtcABb2aWKAe8mVmiHPBmZolywJuZJcoBbyVF0l5JK5o9CjZhl6SK5jMEmhVb98NvYpaU3RFRXewizDqCz+DNAEnrJX1b0ouSfivpL/LLKyT9Mj8X9yJJJ+WXHy/pUUn/kX+cmd9VN0n35Oc1/zdJvYrWKSt5DngrNb3eNUQztdm67RFxGvB/yM1iCfB94MGIGAU8DNyZX34n8KuIqCI3T8xL+eVDgFkRMQLYBlycaW/MDsHfZLWSImlXRBxzkOXrgXMj4pX8pG6vR8RASW8CJ0TE2/nlGyNikKRGYHBE/KnZPiqAX0Tupg1I+gpQFhG3dEDXzN7DZ/Bm74gWnrfFn5o934s/57IicsCbvWNqs5/P5p//htxMlgCfBX6df74IuBr23zO2b0cVadZaPruwUtNL0opmr5+KiH2XSvaX9AK5s/BP55fNIHdnpRvI3WXp8vzy64A6SVeQO1O/mtwMgWadhsfgzdg/Bl8TEW8WuxazQvEQjZlZonwGb2aWKJ/Bm5klygFvZpYoB7yZWaIc8GZmiXLAm5kl6v8DGCli6s/0zxkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 128...\n",
      "Epoch: 0, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 1, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 2, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 3, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 4, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 5, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 6, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 7, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 8, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 9, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 10, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 11, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 12, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 13, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 14, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 15, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 16, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 17, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 18, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 19, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 20, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 21, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 22, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 23, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 24, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 25, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 26, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 27, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 28, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 29, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 30, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 31, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 32, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 33, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 34, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 35, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 36, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 37, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 38, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 39, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 40, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 41, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 42, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 43, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 44, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 45, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 46, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 47, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 48, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 49, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 50, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 51, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 52, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 53, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 54, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 55, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 56, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 57, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 58, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 59, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 60, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 61, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 62, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 63, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 64, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 65, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 66, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 67, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 68, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 69, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 70, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 71, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 72, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 73, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 74, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 75, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 76, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 77, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 78, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 79, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 80, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 81, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 82, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 83, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 84, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 85, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 86, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 87, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 88, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 89, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 90, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 91, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 92, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 93, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 94, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 95, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 96, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 97, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 98, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Epoch: 99, Train loss: 6637247.5823, Train acc: 0.2742, Eval loss: 829655.9478, Eval acc: 0.2753\n",
      "Training with batch size 128 took 74.06 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define mini-batch sizes to test\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size {batch_size}...\")\n",
    "\n",
    "    # Initialize parameters and hyperparameters\n",
    "    W2 = np.random.randn(300, 4)\n",
    "    eta = 0.001\n",
    "    n_epochs = 100\n",
    "    train_loss = []\n",
    "    eval_loss = []\n",
    "    train_acc = []\n",
    "    eval_acc = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        # Shuffle training data\n",
    "        indices = np.random.permutation(x_train.shape[0])\n",
    "        x_train = x_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        # Loop over mini-batches\n",
    "        for i in range(0, x_train.shape[0], batch_size):\n",
    "            # Get mini-batch\n",
    "            x_batch = x_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            # Compute loss and gradient\n",
    "            y_hat = softmax(np.dot(x_batch, W2))\n",
    "            loss = cross_entropy_loss(y_batch, y_hat)\n",
    "            # loss = -np.mean(y_batch * np.log(y_hat))\n",
    "            dW = np.dot(x_batch.T, y_hat - y_batch)\n",
    "\n",
    "            # Update weights\n",
    "            W2 -= eta * dW\n",
    "\n",
    "        # Compute loss and accuracy on training set\n",
    "        train_probs = softmax(x_train.dot(W2))\n",
    "        train_loss.append(cross_entropy_loss(y_train, train_probs))\n",
    "        # train_loss.append(-np.mean(y_train * np.log(train_probs)))\n",
    "        train_pred = np.argmax(train_probs, axis=1)\n",
    "    \n",
    "        train_acc.append(np.mean(train_pred == np.argmax(y_train, axis=1)))\n",
    "\n",
    "        # Compute loss and accuracy on validation set\n",
    "        eval_probs = softmax(x_val.dot(W2))\n",
    "        eval_loss.append(cross_entropy_loss(y_val, eval_probs))\n",
    "        # eval_loss.append(-np.mean(y_val * np.log(eval_probs)))\n",
    "        eval_pred = np.argmax(eval_probs, axis=1)\n",
    "        eval_acc.append(np.mean(eval_pred == np.argmax(y_val, axis=1)))\n",
    "\n",
    "        # Print progress\n",
    "        print(\"Epoch: %d, Train loss: %.4f, Train acc: %.4f, Eval loss: %.4f, Eval acc: %.4f\" % (\n",
    "            epoch, train_loss[-1], train_acc[-1], eval_loss[-1], eval_acc[-1]))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Training with batch size {batch_size} took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(eval_loss, label='eval')\n",
    "    plt.plot(train_acc, label='train acc')\n",
    "    plt.plot(eval_acc, label='eval acc')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('value')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 78. Training on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 1...\n",
      "Epoch: 0, Train loss: 0.4029, Train acc: 0.8543, Eval loss: 0.4161, Eval acc: 0.8493\n",
      "Epoch: 1, Train loss: 0.3412, Train acc: 0.8771, Eval loss: 0.3718, Eval acc: 0.8654\n",
      "Epoch: 2, Train loss: 0.3062, Train acc: 0.8910, Eval loss: 0.3494, Eval acc: 0.8746\n",
      "Epoch: 3, Train loss: 0.2766, Train acc: 0.9018, Eval loss: 0.3301, Eval acc: 0.8813\n",
      "Epoch: 4, Train loss: 0.2646, Train acc: 0.9056, Eval loss: 0.3265, Eval acc: 0.8847\n",
      "Epoch: 5, Train loss: 0.2544, Train acc: 0.9095, Eval loss: 0.3259, Eval acc: 0.8848\n",
      "Epoch: 6, Train loss: 0.2403, Train acc: 0.9151, Eval loss: 0.3218, Eval acc: 0.8875\n",
      "Epoch: 7, Train loss: 0.2298, Train acc: 0.9182, Eval loss: 0.3194, Eval acc: 0.8887\n",
      "Epoch: 8, Train loss: 0.2259, Train acc: 0.9206, Eval loss: 0.3248, Eval acc: 0.8870\n",
      "Epoch: 9, Train loss: 0.2184, Train acc: 0.9233, Eval loss: 0.3230, Eval acc: 0.8878\n",
      "Epoch: 10, Train loss: 0.2117, Train acc: 0.9255, Eval loss: 0.3220, Eval acc: 0.8899\n",
      "Epoch: 11, Train loss: 0.2096, Train acc: 0.9260, Eval loss: 0.3229, Eval acc: 0.8906\n",
      "Epoch: 12, Train loss: 0.2062, Train acc: 0.9267, Eval loss: 0.3301, Eval acc: 0.8891\n",
      "Epoch: 13, Train loss: 0.1989, Train acc: 0.9298, Eval loss: 0.3296, Eval acc: 0.8891\n",
      "Epoch: 14, Train loss: 0.1958, Train acc: 0.9311, Eval loss: 0.3306, Eval acc: 0.8877\n",
      "Epoch: 15, Train loss: 0.1965, Train acc: 0.9296, Eval loss: 0.3408, Eval acc: 0.8879\n",
      "Epoch: 16, Train loss: 0.1913, Train acc: 0.9321, Eval loss: 0.3388, Eval acc: 0.8888\n",
      "Epoch: 17, Train loss: 0.1867, Train acc: 0.9341, Eval loss: 0.3402, Eval acc: 0.8885\n",
      "Epoch: 18, Train loss: 0.1854, Train acc: 0.9346, Eval loss: 0.3411, Eval acc: 0.8874\n",
      "Epoch: 19, Train loss: 0.1830, Train acc: 0.9349, Eval loss: 0.3469, Eval acc: 0.8885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\duc\\TAI_LIEU_HUST\\20222\\Thực tập kỹ thuật\\Neural_Networks\\70_79.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_train[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(x_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_hat, torch\u001b[39m.\u001b[39margmax(y_batch, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dotha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32me:\\duc\\TAI_LIEU_HUST\\20222\\Thực tập kỹ thuật\\Neural_Networks\\70_79.ipynb Cell 28\u001b[0m in \u001b[0;36mMyModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/duc/TAI_LIEU_HUST/20222/Th%E1%BB%B1c%20t%E1%BA%ADp%20k%E1%BB%B9%20thu%E1%BA%ADt/Neural_Networks/70_79.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\dotha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\dotha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Define neural network architecture\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(300, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define mini-batch sizes to test\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "# Move data to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.Tensor(x_train).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "x_val = torch.Tensor(x_val).to(device)\n",
    "y_val = torch.Tensor(y_val).to(device)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size {batch_size}...\")\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = MyModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(100):\n",
    "        # Shuffle training data\n",
    "        indices = torch.randperm(x_train.shape[0])\n",
    "        x_train = x_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        # Loop over mini-batches\n",
    "        for i in range(0, x_train.shape[0], batch_size):\n",
    "            # Get mini-batch\n",
    "            x_batch = x_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            y_hat = model(x_batch)\n",
    "            loss = criterion(y_hat, torch.argmax(y_batch, dim=1))\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Compute loss and accuracy on training set\n",
    "        with torch.no_grad():\n",
    "            train_probs = model(x_train)\n",
    "            train_loss = criterion(train_probs, torch.argmax(y_train, dim=1))\n",
    "            train_pred = torch.argmax(train_probs, dim=1)\n",
    "            train_acc = torch.mean(\n",
    "                (train_pred == torch.argmax(y_train, dim=1)).float())\n",
    "\n",
    "            # Compute loss and accuracy on validation set\n",
    "            eval_probs = model(x_val)\n",
    "            eval_loss = criterion(eval_probs, torch.argmax(y_val, dim=1))\n",
    "            eval_pred = torch.argmax(eval_probs, dim=1)\n",
    "            eval_acc = torch.mean(\n",
    "                (eval_pred == torch.argmax(y_val, dim=1)).float())\n",
    "\n",
    "            # Print progress\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}, Eval loss: {eval_loss:.4f}, Eval acc: {eval_acc:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Training with batch size {batch_size} took {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size 1...\n",
      "Epoch: 0, Train loss: 0.9543, Train acc: 0.8313, Eval loss: 0.9557, Eval acc: 0.8305\n",
      "Epoch: 1, Train loss: 0.9321, Train acc: 0.8488, Eval loss: 0.9351, Eval acc: 0.8456\n",
      "Epoch: 2, Train loss: 0.9118, Train acc: 0.8714, Eval loss: 0.9179, Eval acc: 0.8627\n",
      "Epoch: 3, Train loss: 0.9034, Train acc: 0.8761, Eval loss: 0.9111, Eval acc: 0.8658\n",
      "Epoch: 4, Train loss: 0.8916, Train acc: 0.8863, Eval loss: 0.9016, Eval acc: 0.8723\n",
      "Epoch: 5, Train loss: 0.8877, Train acc: 0.8883, Eval loss: 0.8989, Eval acc: 0.8733\n",
      "Epoch: 6, Train loss: 0.8852, Train acc: 0.8901, Eval loss: 0.8974, Eval acc: 0.8723\n",
      "Epoch: 7, Train loss: 0.8805, Train acc: 0.8942, Eval loss: 0.8938, Eval acc: 0.8761\n",
      "Epoch: 8, Train loss: 0.8783, Train acc: 0.8967, Eval loss: 0.8921, Eval acc: 0.8777\n",
      "Epoch: 9, Train loss: 0.8740, Train acc: 0.8969, Eval loss: 0.8884, Eval acc: 0.8780\n",
      "Epoch: 10, Train loss: 0.8749, Train acc: 0.8993, Eval loss: 0.8908, Eval acc: 0.8782\n",
      "Epoch: 11, Train loss: 0.8714, Train acc: 0.9010, Eval loss: 0.8877, Eval acc: 0.8791\n",
      "Epoch: 12, Train loss: 0.8737, Train acc: 0.8974, Eval loss: 0.8904, Eval acc: 0.8755\n",
      "Epoch: 13, Train loss: 0.8686, Train acc: 0.9018, Eval loss: 0.8863, Eval acc: 0.8776\n",
      "Epoch: 14, Train loss: 0.8695, Train acc: 0.9019, Eval loss: 0.8877, Eval acc: 0.8771\n",
      "Epoch: 15, Train loss: 0.8669, Train acc: 0.9031, Eval loss: 0.8844, Eval acc: 0.8803\n",
      "Epoch: 16, Train loss: 0.8685, Train acc: 0.9021, Eval loss: 0.8874, Eval acc: 0.8768\n",
      "Epoch: 17, Train loss: 0.8652, Train acc: 0.9052, Eval loss: 0.8851, Eval acc: 0.8789\n",
      "Epoch: 18, Train loss: 0.8660, Train acc: 0.9038, Eval loss: 0.8854, Eval acc: 0.8788\n",
      "Epoch: 19, Train loss: 0.8646, Train acc: 0.9061, Eval loss: 0.8843, Eval acc: 0.8803\n",
      "Epoch: 20, Train loss: 0.8629, Train acc: 0.9062, Eval loss: 0.8832, Eval acc: 0.8793\n",
      "Epoch: 21, Train loss: 0.8642, Train acc: 0.9066, Eval loss: 0.8861, Eval acc: 0.8775\n",
      "Epoch: 22, Train loss: 0.8656, Train acc: 0.9054, Eval loss: 0.8872, Eval acc: 0.8754\n",
      "Epoch: 23, Train loss: 0.8621, Train acc: 0.9074, Eval loss: 0.8834, Eval acc: 0.8797\n",
      "Epoch: 24, Train loss: 0.8624, Train acc: 0.9064, Eval loss: 0.8833, Eval acc: 0.8788\n",
      "Epoch: 25, Train loss: 0.8621, Train acc: 0.9082, Eval loss: 0.8845, Eval acc: 0.8782\n",
      "Epoch: 26, Train loss: 0.8613, Train acc: 0.9083, Eval loss: 0.8838, Eval acc: 0.8787\n",
      "Epoch: 27, Train loss: 0.8597, Train acc: 0.9085, Eval loss: 0.8817, Eval acc: 0.8792\n",
      "Epoch: 28, Train loss: 0.8598, Train acc: 0.9096, Eval loss: 0.8827, Eval acc: 0.8785\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Define mini-batch sizes to test\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.Tensor(x_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "x_val_tensor = torch.Tensor(x_val)\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "\n",
    "# Define neural network architecture\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(300, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 4)\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size {batch_size}...\")\n",
    "\n",
    "    # Initialize lists to store loss and accuracy values\n",
    "    train_loss = []\n",
    "    eval_loss = []\n",
    "    train_acc = []\n",
    "    eval_acc = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(100):\n",
    "        # Shuffle training data\n",
    "        indices = torch.randperm(x_train_tensor.shape[0])\n",
    "        x_train_tensor = x_train_tensor[indices]\n",
    "        y_train_tensor = y_train_tensor[indices]\n",
    "\n",
    "        # Loop over mini-batches\n",
    "        for i in range(0, x_train_tensor.shape[0], batch_size):\n",
    "            # Get mini-batch\n",
    "            x_batch = x_train_tensor[i:i+batch_size]\n",
    "            y_batch = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_hat = model(x_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(y_hat, y_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        # Compute loss and accuracy on training set\n",
    "        train_probs = torch.nn.functional.softmax(model(x_train_tensor), dim=1)\n",
    "        train_loss.append(criterion(train_probs, y_train_tensor).item())\n",
    "        train_pred = torch.argmax(train_probs, axis=1)\n",
    "        train_acc.append(torch.mean((train_pred == torch.argmax(y_train_tensor, dim=1)).float()))\n",
    "\n",
    "        # Compute loss and accuracy on validation set\n",
    "        eval_probs = torch.nn.functional.softmax(model(x_val_tensor), dim=1)\n",
    "        eval_loss.append(criterion(eval_probs, y_val_tensor).item())\n",
    "        eval_pred = torch.argmax(eval_probs, axis=1)\n",
    "        eval_acc.append(torch.mean((eval_pred == torch.argmax(y_val_tensor, dim=1)).float()))\n",
    "\n",
    "        # Print progress\n",
    "        print(\"Epoch: %d, Train loss: %.4f, Train acc: %.4f, Eval loss: %.4f, Eval acc: %.4f\" % (\n",
    "            epoch, train_loss[-1], train_acc[-1], eval_loss[-1], eval_acc[-1]))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Training with batch size {batch_size} took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(eval_loss, label='eval')\n",
    "    plt.plot(train_acc, label='train acc')\n",
    "    plt.plot(eval_acc, label='eval acc')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('value')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
